
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Discuss about devops activities">
      
      
      
        <link rel="canonical" href="https://github.com/devops-den/blog/2023/11/13/emqx-and-kafka-app/">
      
      
      
        <link rel="next" href="../../../../2024/11/14/kafka-offsets/">
      
      
      <link rel="icon" href="../../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.44">
    
    
      
        <title>Emqx and Kafka app - DevopsDen</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.0253249f.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#emqx-and-kafka-app" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="DevopsDen" class="md-header__button md-logo" aria-label="DevopsDen" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            DevopsDen
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Emqx and Kafka app
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="DevopsDen" class="md-nav__button md-logo" aria-label="DevopsDen" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    DevopsDen
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Blog
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_2" >
        
          
          <label class="md-nav__link" for="__nav_1_2" id="__nav_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../archive/2024/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../archive/2023/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2023
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#emqx" class="md-nav__link">
    <span class="md-ellipsis">
      EMQX
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kafka" class="md-nav__link">
    <span class="md-ellipsis">
      KAFKA
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setting-up-emqx" class="md-nav__link">
    <span class="md-ellipsis">
      Setting up EMQX
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Setting up EMQX">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-running-emqx-service" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1: Running EMQX service
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-create-emqx-publishersubscriber-files-using-python-programming" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Create emqx publisher/subscriber files using python programming
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Step 2: Create emqx publisher/subscriber files using python programming">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-using-paho-mqtt-python-module" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1: using paho-mqtt python module
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-install-the-paho-mqtt-client" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Install the Paho Mqtt Client
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-create-a-emqx-python-publisher" class="md-nav__link">
    <span class="md-ellipsis">
      Step 3: Create a emqx python publisher.
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content md-content--post" data-md-component="content">
    <div class="md-sidebar md-sidebar--post" data-md-component="sidebar" data-md-type="navigation">
      <div class="md-sidebar__scrollwrap">
        <div class="md-sidebar__inner md-post">
          <nav class="md-nav md-nav--primary">
            <div class="md-post__back">
              <div class="md-nav__title md-nav__container">
                <a href="../../../../" class="md-nav__link">
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
                  <span class="md-ellipsis">
                    Back to index
                  </span>
                </a>
              </div>
            </div>
            
            <ul class="md-post__meta md-nav__list">
              <li class="md-nav__item md-nav__item--section">
                <div class="md-post__title">
                  <span class="md-ellipsis">
                    Metadata
                  </span>
                </div>
                <nav class="md-nav">
                  <ul class="md-nav__list">
                    <li class="md-nav__item">
                      <div class="md-nav__link">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"/></svg>
                        <time datetime="2023-11-13 00:00:00" class="md-ellipsis">Monday, November 13, 2023</time>
                      </div>
                    </li>
                    
                    
                    
                      
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7z"/></svg>
                          <span class="md-ellipsis">
                            
                              16 min read
                            
                          </span>
                        </div>
                      </li>
                    
                  </ul>
                </nav>
              </li>
            </ul>
          </nav>
          
        </div>
      </div>
    </div>
    <article class="md-content__inner md-typeset">
      
        


<h1 id="emqx-and-kafka-app">Emqx and Kafka app</h1>
<p>The goal of this document is to use Kafka to process massive amounts of data from Internet of Things (IOT) devices in an efficient manner. However, since Kafka was not intended for IOT devices, the integration of EMQX—which uses the MQTT lightweight protocol—with Kafka can elevate a variety of opportunities to process the data in real-time, greatly benefiting time-sensitive applications.</p>
<!-- more -->
<h2 id="introduction">Introduction</h2>
<h3 id="emqx">EMQX</h3>
<p>EMQX is an open-source, highly scalable, and feature-rich MQTT broker designed for IoT and real-time messaging applications. It supports up to 100 million concurrent IoT device connections per cluster while maintaining a throughput of 1 million messages per second and a millisecond latency.</p>
<p>EMQX supports various protocols, including MQTT (3.1, 3.1.1, and 5.0), HTTP, QUIC, and WebSocket. It also provides secure bi-directional communication with MQTT over TLS/SSL and various authentication mechanisms, ensuring reliable and efficient communication infrastructure for IoT devices and applications.</p>
<h3 id="kafka">KAFKA</h3>
<p>Apache Kafka is a widely used open-source distributed event streaming platform that can handle the real-time transfer of data streams between applications and systems. However, Kafka is not built for edge IoT communication and Kafka clients require a stable network connection and more hardware resources. In the IoT realm, data generated from devices and applications are transmitted using the lightweight MQTT protocol. EMQX’s integration with Kafka/Confluent enables users to stream MQTT data seamlessly into or from Kafka. MQTT data streams are ingested into Kafka topics, ensuring real-time processing, storage, and analytics. Conversely, Kafka topics data can be consumed by MQTT devices, enabling timely actions.</p>
<p>We will accomplish the following architecture in this tutorial.</p>
<p><img alt="emqx-kafka" src="../../../../images/emqx-kafka.jpg" /></p>
<h2 id="setting-up-emqx">Setting up EMQX</h2>
<h3 id="step-1-running-emqx-service">Step 1: Running EMQX service</h3>
<p>When setting up the emqx server locally, Docker is a really helpful tool. It can remove a lot of steps and allow us to run the emqx server configuration with just two commands, as shown below.</p>
<pre><code class="language-docker">docker pull emqx/emqx
docker run -d --name emqx -p 1883:1883 -p 8083:8083 -p 8084:8084 -p 8883:8883 -p 18083:18083 emqx/emqx
</code></pre>
<p>We can also pull and execute the emqx docker image on the Windows computer by using docker desktop.</p>
<p><img alt="emqx-windows-docker" src="../../../../images/emqx/emqx-windows.png" /></p>
<p>EMQX supports the following message transmission protocols, and once you run the docker image, you should be able to see the logs that contain the details about the ports on which emqx services are running. The listener in EMQX is set up to receive requests from MQTT clients.</p>
<pre><code>- TCP: port 1883
- SSL: port 8883
- Websocket listener: 8083
- Secure websocket listener: 8084
- For UI Dashboard: 18083
</code></pre>
<p><img alt="running emqx docker" src="../../../../images/emqx/running-emqx-docker.png" /></p>
<p>In EMQX, Dashboard is a web-based graphic interface to manage and monitor EMQX and connected devices in real time.
 Access the endpoint <code>&lt;ipaddress&gt;:18083</code></p>
<p><img alt="webpage" src="../../../../images/emqx/webpage.png" /></p>
<p>Login into the dashboard using default credentials.</p>
<pre><code>username: admin
password: public
</code></pre>
<p>Upon logging in for the first time, you will be prompted to reset your password, which will then take you to the emqx dashboard.</p>
<p><img alt="dashboard" src="../../../../images/emqx/dashboard.png" /></p>
<h3 id="step-2-create-emqx-publishersubscriber-files-using-python-programming">Step 2: Create emqx publisher/subscriber files using python programming</h3>
<ul>
<li>
<h4 id="step-1-using-paho-mqtt-python-module">Step 1: using paho-mqtt python module</h4>
<p>This article primarily explains how to use the paho-mqtt client and construct message, connection, and subscription functions in Python between the MQTT client and MQTT broker.</p>
</li>
<li>
<h4 id="step-2-install-the-paho-mqtt-client">Step 2: Install the Paho Mqtt Client</h4>
<p><code>pip3 install paho-mqtt</code></p>
</li>
<li>
<h4 id="step-3-create-a-emqx-python-publisher">Step 3: Create a emqx python publisher.</h4>
<p>```
from paho.mqtt import client as mqtt_client
import random
import logging
import time</p>
<h1 id="create-an-mqtt-connection">Create an MQTT Connection</h1>
<p>broker      = '192.168.48.1'
port        = 1883
topic       = "python/mqtt"
client_id   = f'python-mqtt-{random.randint(0, 1000)}'
username    = "admin"
password    = "public"</p>
<h1 id="auto-reconnect-for-reliable-connection">Auto reconnect for reliable connection</h1>
<p>FIRST_RECONNECT_DELAY   = 1
RECONNECT_RATE          = 2
MAX_RECONNECT_COUNT     = 12
MAX_RECONNECT_DELAY     = 60</p>
<h1 id="on_connect-callback-function-for-connecting-the-broker">on_connect callback function for connecting the broker.</h1>
<h1 id="this-function-is-called-after-client-call-has-successfully-connected">This function is called after client call has successfully connected.</h1>
<p>def connect_mqtt():
    def on_connect(client, userdata, flags, rc):
        if rc == 0:
            print("Connected to MQTT Broker!")
        else:
            print("Failed to connect, return code %d\n", rc)</p>
<pre><code>def on_disconnect(client, userdata, rc):
    logging.info("Disconnected with result code: %s", rc)
    reconnect_count, reconnect_delay = 0, FIRST_RECONNECT_DELAY
    while reconnect_count &lt; MAX_RECONNECT_COUNT:
        logging.info("Reconnecting in %d seconds...", reconnect_delay)
        time.sleep(reconnect_delay)

        try:
            client.reconnect()
            logging.info("Reconnected successfully!")
            return
        except Exception as err:
            logging.error("%s. Reconnect failed. Retrying...", err)

        reconnect_delay *= RECONNECT_RATE
        reconnect_delay = min(reconnect_delay, MAX_RECONNECT_DELAY)
        reconnect_count += 1
    logging.info("Reconnect failed after %s attempts. Exiting...", reconnect_count)

# Set connecting Client ID
client = mqtt_client.Client(client_id)
client.username_pw_set(username, password)
client.on_connect = on_connect
client.connect(broker, port)
client.on_disconnect = on_disconnect
return client
</code></pre>
<h1 id="publisher-code">publisher code</h1>
<p>def publish(client):
    msg_count = 1
    while True:
        time.sleep(1)
        msg = f"messages: {msg_count}"
        result = client.publish(topic, msg)
        status = result[0]
        if status == 0:
            print(f"Send <code>{msg}</code> to topic <code>{topic}</code>")
        else:
            print(f"Failed to send message to topic {topic}")
        msg_count += 1
        if msg_count &gt; 5:
            break</p>
<p>def run():
    client = connect_mqtt()
    client.loop_start()
    publish(client)
    client.loop_forever()</p>
<p>if <strong>name</strong> == "<strong>main</strong>":
    run()
```</p>
</li>
<li>
<h4 id="step-4-create-a-emqx-python-subscriber">Step 4: Create a emqx python subscriber.</h4>
<p>```
import random
from paho.mqtt import client as mqtt_client</p>
<h1 id="create-an-mqtt-connection_1">Create an MQTT Connection</h1>
<p>broker      = '192.168.48.1'
port        = 1883
topic       = "python/mqtt"
client_id   = f'subscribe-{random.randint(0, 1000)}'
username    = "admin"
password    = "public"</p>
<p>def connect_mqtt() -&gt; mqtt_client:
    def on_connect(client, userdata, flags, rc):
        if rc == 0:
            print("Connected to MQTT Broker!")
        else:
            print("Failed to connect, return code %d\n", rc)</p>
<pre><code>client = mqtt_client.Client(client_id)
client.username_pw_set(username, password)
client.on_connect = on_connect
client.connect(broker, port)
return client
</code></pre>
<p>def subscribe(client: mqtt_client):
    def on_message(client, userdata, msg):
        print(f"Received <code>{msg.payload.decode()}</code> from <code>{msg.topic}</code> topic")</p>
<pre><code>client.subscribe(topic)
client.on_message = on_message
</code></pre>
<p>def run():
    client = connect_mqtt()
    subscribe(client)
    client.loop_forever()</p>
<p>if <strong>name</strong> == "<strong>main</strong>":
    run()
```</p>
<blockquote>
<p><strong><em>NOTE:</em></strong> These two files are quite basic; the publisher will send five messages before stopping, and the subscriber will be in an endless loop of receiving messages from the publisher. You can modify the publisher logic to transmit messages continuously by deleting the block below.
<code>msg_count += 1
    if msg_count &gt; 5:
        break</code></p>
</blockquote>
</li>
<li>
<h4 id="step-5-execute-the-subscriber-and-publisher">Step 5: Execute the subscriber and Publisher</h4>
<p>Run the publisher program in a separate terminal session after completing the subscriber program in the first one. The result should look somewhat like this:</p>
<p><img alt="emqx execution" src="../../../../images/emqx/execution-emqx.png" /></p>
</li>
</ul>
<h3 style="text-align: center;"> *** End of EMQX setup *** </h3>

<h2 id="setting-up-kafka-assuming-on-ubuntu-platform">Setting up KAFKA (Assuming on Ubuntu platform)</h2>
<p>For those who are unfamiliar with Kafka, the diagram below provides a high-level explanation of the concept. (there is lot more to Kafka, such Zookeeper, Consumer Groups, Partitions, etc., but we will leave it for another time.)</p>
<p><img alt="kafka setup" src="../../../../images/kafka/kafka-setup.png" /></p>
<p>Kafka divides data into topics, which are categories or feed names to which records are published. Producers publish messages to a particular topic. These messages can take any format; popular formats are JSON and Avro. For instance, on a social media platform, a producer may publish messages to a topic called posts each time a user creates a post. Consumers subscribe to a topic in order to consume the records published by producers. In the example given for the social media platform, there may be a consumer set up to consume the posts topic in order to verify the post's safety before it is published to the global feed, and another consumer may asynchronously send notifications to the user's followers.</p>
<h3 id="step-1-installing-java">Step 1: Installing Java</h3>
<p>Since Oracle Java is now commercially accessible, we are using its open-source version OpenJDK. Apache Kafka can be operated on any platform that supports Java. To install Kafka on an Ubuntu server, follow these steps.</p>
<pre><code>sudo apt update 
sudo apt install default-jdk
</code></pre>
<pre><code>java --version
openjdk 17.0.9 2023-10-17
OpenJDK Runtime Environment (build 17.0.9+9-Ubuntu-122.04)
OpenJDK 64-Bit Server VM (build 17.0.9+9-Ubuntu-122.04, mixed mode, sharing)
</code></pre>
<h3 id="step-2-download-latest-apache-kafka">Step 2: Download latest apache kafka</h3>
<pre><code>wget https://dlcdn.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz
</code></pre>
<p>Extract the archive file,</p>
<pre><code>tar -xzf kafka_2.13-3.6.1.tgz
sudo mv kafka_2.13-3.6.1 /usr/local/kafka
</code></pre>
<h3 id="step-3-running-kafka-service">Step 3: Running Kafka service.</h3>
<p>Now that we have two options for starting the Kafka service, we can choose to run it as a unix service. Alternatively, we can navigate to /usr/local/kafka/bin and run the Kafka script each time.</p>
<blockquote>
<p><strong><em>NOTE:</em></strong> ZooKeeper or KRaft can be used to start Apache Kafka; in this post, we will use ZooKeeper Flow rather of both.</p>
</blockquote>
<ul>
<li>
<h4 id="step-1-creating-system-unit-files">Step 1 - Creating System Unit Files</h4>
<p><code>sudo nano /etc/systemd/system/zookeeper.service</code></p>
<p>And add the following content:</p>
<p>```
[Unit]
Description=Apache Zookeeper server
Documentation=http://zookeeper.apache.org
Requires=network.target remote-fs.target
After=network.target remote-fs.target</p>
<p>[Service]
Type=simple
ExecStart=/usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties
ExecStop=/usr/local/kafka/bin/zookeeper-server-stop.sh
Restart=on-abnormal</p>
<p>[Install]
WantedBy=multi-user.target
```</p>
<p>Save the file and close it.</p>
<p>Next, to create a system unit file for the kafka service:</p>
<p><code>sudo nano /etc/systemd/system/kafka.service</code></p>
<p>Add the following content:</p>
<p>```
[Unit]
Description=Apache Kafka Server
Documentation=http://kafka.apache.org/documentation.html
Requires=zookeeper.service</p>
<p>[Service]
Type=simple
Environment="JAVA_HOME=/usr/lib/jvm/java-1.17.0-openjdk-amd64"
ExecStart=/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties
ExecStop=/usr/local/kafka/bin/kafka-server-stop.sh</p>
<p>[Install]
WantedBy=multi-user.target
```</p>
<p>Reload the systemd daemon to apply new changes.</p>
<p><code>sudo systemctl daemon-reload</code></p>
</li>
<li>
<h4 id="step-2-start-kafka-and-zookeeper-service">Step 2 - Start Kafka and Zookeeper Service</h4>
<p>To start Kafka, you must first start the ZooKeeper service. To start a single-node ZooKeeper instance, use the systemctl command.</p>
<p><code>sudo systemctl start zookeeper</code></p>
<p>Launch the Kafka server now to see the current status:</p>
<p><code>sudo systemctl start kafka
sudo systemctl status kafka</code></p>
<p>```
devops@LAPTOP-JF1PIDLR:~/Documents/Personal/projects/General/emqx-kafka-mongo-messaging-app$ sudo vi /etc/systemd/system/kafka.service
● kafka.service - Apache Kafka Server
 Loaded: loaded (/etc/systemd/system/kafka.service; disabled; vendor preset: enabled)
 Active: active (running) since Tue 2023-12-12 13:41:12 EST; 6s ago
   Docs: http://kafka.apache.org/documentation.html
   Main PID: 50201 (java)
  Tasks: 83 (limit: 9396)
 Memory: 315.5M
 CGroup: /system.slice/kafka.service
         └─50201 /usr/lib/jvm/java-1.17.0-openjdk-amd64/bin/java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -D&gt;</p>
<p>Dec 12 13:41:17 LAPTOP-JF1PIDLR kafka-server-start.sh[50201]: [2023-12-12 13:41:17,600] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
Dec 12 13:41:17 LAPTOP-JF1PIDLR kafka-server-start.sh[50201]: [2023-12-12 13:41:17,614] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
Dec 12 13:41:17 LAPTOP-JF1PIDLR kafka-server-start.sh[50201]: [2023-12-12 13:41:17,634] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
Dec 12 13:41:17 LAPTOP-JF1PIDLR kafka-server-start.sh[50201]: [2023-12-12 13:41:17,638] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
Dec 12 13:41:17 LAPTOP-JF1PIDLR kafka-server-start.sh[50201]: [2023-12-12 13:41:17,651] INFO Kafka version: 3.6.1 (org.apache.kafka.common.utils.AppInfoParser)
Dec 12 13:41:17 LAPTOP-JF1PIDLR kafka-server-start.sh[50201]: [2023-12-12 13:41:17,652] INFO Kafka commitId: 5e3c2b738d253ff5 (org.apache.kafka.common.utils.AppInfoParser)
Dec 12 13:41:17 LAPTOP-JF1PIDLR kafka-server-start.sh[50201]: [2023-12-12 13:41:17,652] INFO Kafka startTimeMs: 1702406477646 (org.apache.kafka.common.utils.AppInfoParser)
Dec 12 13:41:17 LAPTOP-JF1PIDLR kafka-server-start.sh[50201]: [2023-12-12 13:41:17,653] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
Dec 12 13:41:17 LAPTOP-JF1PIDLR kafka-server-start.sh[50201]: [2023-12-12 13:41:17,843] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node LAPTOP-JF1PIDLR.:9092 (&gt;
Dec 12 13:41:17 LAPTOP-JF1PIDLR kafka-server-start.sh[50201]: [2023-12-12 13:41:17,861] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node LAPTOP-JF1PIDLR.:9
```</p>
<p>This completes the installation of Kafka. The next section of the tutorial will assist you in interacting with the Kafka server.</p>
</li>
</ul>
<h3 id="step-4-create-a-topic-in-kafka">Step 4: Create a Topic in Kafka</h3>
<p>To begin working with Kafka, create a topic called "emqx-to-kafka" with a single partition and a single replica. Kafka provides several pre-built shell scripts for this purpose.</p>
<pre><code>cd /usr/local/kafka
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic emqx-to-kafka

Created topic emqx-to-kafka.
</code></pre>
<p>You can run the same command above to create multiple topics. After that, you can run the following command to see the created topics on Kafka. The replication factor specifies how many copies of data will be created. Since we are running with a single instance, keep this value 1. Set the partition options as the number of brokers you want your data to be split between.</p>
<pre><code>devops@LAPTOP-JF1PIDLR:/usr/local/kafka$ bin/kafka-topics.sh --list --bootstrap-server localhost:9092

emqx-to-kafka
</code></pre>
<p>Moreover, you can use the describe command to view information like the new topic's partition count:</p>
<pre><code>devops@LAPTOP-JF1PIDLR:/usr/local/kafka$ bin/kafka-topics.sh --describe --topic emqx-to-kafka --bootstrap-server localhost:9092
Topic: emqx-to-kafka    TopicId: BPDpQiOvQ2WDGWPn45d99w PartitionCount: 1       ReplicationFactor: 1    Configs: 
        Topic: emqx-to-kafka    Partition: 0    Leader: 0       Replicas: 0     Isr: 0
</code></pre>
<h3 id="step-4-writing-event-into-kafka-topic">Step 4: Writing event into Kafka topic</h3>
<p>Run the producer client to write a few events into your topic. By default, each line you enter will result in a separate event being written to the topic. A Kafka client communicates with the Kafka brokers via the network for writing (or reading) events. Once the brokers receive the events, they will store them for as long as you need—even forever.</p>
<pre><code>bin/kafka-console-producer.sh --topic emqx-to-kafka --bootstrap-server localhost:9092
&gt;
</code></pre>
<blockquote>
<p><strong><em>NOTE:</em></strong> In this case, <code>&gt;</code> indicates that it entered a prompt and requested that you add messages, which will be transmitted to the designated topic and the Kafka broker.</p>
</blockquote>
<p>Example instance,</p>
<pre><code>devops@LAPTOP-JF1PIDLR:/usr/local/kafka$ bin/kafka-console-producer.sh --topic emqx-to-kafka --bootstrap-server localhost:9092
&gt;
&gt;First kafka producer message
&gt;Second Kafka producer message
&gt;
</code></pre>
<p>Ctrl-C can be used to end the producer client at any moment.</p>
<h3 id="step-5-reading-the-eventn-from-kafka-topic">Step 5: Reading the eventn from Kafka topic</h3>
<p>To read the events you just created, open a second terminal session and launch the consumer client:</p>
<pre><code>devops@LAPTOP-JF1PIDLR:/usr/local/kafka$ bin/kafka-console-consumer.sh --topic emqx-to-kafka --from-beginning --bootstrap-server localhost:9092

First kafka producer message
Second Kafka producer message
</code></pre>
<p>The consumer client can be stopped at any moment by using Ctrl-C. It began reading the buffered messages as soon as you hit the consumer command.</p>
<p>Feel free to get hands-on: for instance, write more events by switching back to your producer terminal (previous step), and observe how the events appear instantly in your consumer terminal. Events in Kafka are durably stored, so you can read them as many times as you would like by opening another terminal session and repeating the previous command.</p>
<blockquote>
<p><strong><em>NOTE:</em></strong> An option in the kakfa to select the location to read the messages from makes it very important to ensure consistency with data and avoid redundant records in time-sensitive applications.
   <code>--offset earlier/latest</code></p>
<p>The default value for this flag is latest, which implies that Kafka will read only messages with the most recent offset value if you do not specify it. The alternative is earliest, which indicates that Kafka will read messages from the offset where it read the most recent message.</p>
<p>For instance, if we assume 0 1 2 and 3 4 5 are the producer messages and assume kafka red and processed 0 1 2. Later, due to some glitch, kafka service was restarted. In case of "latest," it will wait for new messages to come in and skip 3 4 5 messages; in case of "earliest," it will start reading from 3 4 5 and then latest</p>
<p>In the event that there is a lag in the kafka, the application may receive outdated entries if it is expecting real-time data and is using the earlier option.</p>
</blockquote>
<p>Thus far, we have examined how to set up Kafka and handle messages using the CLI. The next step involves sending and receiving Kafka messages using the Python programming language.</p>
<h3 id="step-6-kafka-producer-python-module">Step 6: Kafka producer python module</h3>
<pre><code>import json
from logging import log
from kafka import KafkaProducer
from kafka.errors import KafkaError

# produce json messages
# configure multiple retries
# produce asynchronously with callbacks
producer = KafkaProducer(bootstrap_servers=['localhost:9092'],
                         retries=5,
                         value_serializer=lambda m: json.dumps(m).encode('ascii'))

def on_send_success(record_metadata):
    print(&quot;%s:%d:%d&quot; % (record_metadata.topic, 
                                 record_metadata.partition,
                                 record_metadata.offset))

def on_send_error(excp):
    log.error('I am an errback', exc_info=excp)
    # handle exception

for item in range(10):
    producer.send('emqx-to-kafka', {item: 'awesome-' + str(item**2)}).add_callback(on_send_success).add_errback(on_send_error)

# block until all async messages are sent
producer.flush()
</code></pre>
<h3 id="step-7-kafka-consumer-python-module">Step 7: Kafka consumer python module</h3>
<pre><code>import json
from kafka import KafkaConsumer

# To consume latest messages and auto-commit offsets
# consume json messages
# StopIteration if no message after 1sec
# auto_offset_reset='earliest', enable_auto_commit=False
consumer = KafkaConsumer(bootstrap_servers='localhost:9092',
                         auto_offset_reset='latest', 
                         enable_auto_commit=True,
                         consumer_timeout_ms=1000,
                         value_deserializer=lambda m: json.loads(m.decode('ascii')))

# Subscribe to a regex topic pattern
consumer.subscribe(pattern='^emqx.*')

while True:
    for message in consumer:
        # message value and key are raw bytes -- decode if necessary!
        # e.g., for unicode: `message.value.decode('utf-8')`
        print (&quot;%s:%d:%d: data=%s&quot; % (message.topic, message.partition,
                                            message.offset, message.value))
</code></pre>
<p><img alt="kafka producer and consumer run" src="../../../../images/kafka/kafka-exec.png" /></p>
<h3 style="text-align: center;"> *** End of Kafka setup *** </h3>

<h2 id="emqx-kafka-together">EMQX + KAFKA together</h2>
<p>After learning how EMQX and Kafka function separately up till now, it is time to combine the two to achieve better outcomes. To do this, simply combine the logics of EMQX subscribers and Kafka producers. The combined output will look like this:</p>
<pre><code>import random
import json
from logging import log
from kafka import KafkaProducer
from kafka.errors import KafkaError
from paho.mqtt import client as mqtt_client

# Create an MQTT Connection
broker      = '192.168.48.1'
port        = 1883
topic       = &quot;python/mqtt&quot;
client_id   = f'subscribe-{random.randint(0, 1000)}'
username    = &quot;admin&quot;
password    = &quot;public&quot;

# produce json messages
# configure multiple retries
# produce asynchronously with callbacks
producer = KafkaProducer(bootstrap_servers=['localhost:9092'],
                         retries=5,
                         value_serializer=lambda m: json.dumps(m).encode('ascii'))

def connect_mqtt() -&gt; mqtt_client:
    def on_connect(client, userdata, flags, rc):
        if rc == 0:
            print(&quot;Connected to MQTT Broker!&quot;)
        else:
            print(&quot;Failed to connect, return code %d\n&quot;, rc)

    client = mqtt_client.Client(client_id)
    client.username_pw_set(username, password)
    client.on_connect = on_connect
    client.connect(broker, port)
    return client

def subscribe(client: mqtt_client):
    def on_message(client, userdata, msg):
        print(f&quot;Received `{msg.payload.decode()}` from `{msg.topic}` topic&quot;)
        producer.send('emqx-to-kafka', {&quot;data&quot;: msg.payload.decode()}).add_callback(on_send_success).add_errback(on_send_error)
        # block until all async messages are sent
        producer.flush()

    client.subscribe(topic)
    client.on_message = on_message

def run():
    client = connect_mqtt()
    subscribe(client)
    client.loop_forever()

def on_send_success(record_metadata):
    print(&quot;%s:%d:%d&quot; % (record_metadata.topic, 
                                 record_metadata.partition,
                                 record_metadata.offset))

def on_send_error(excp):
    log.error('I am an errback', exc_info=excp)
    # handle exception

if __name__ == &quot;__main__&quot;:
    run()
</code></pre>
<p>The primary and most significant modification to the current EMQX subscriber logic is that, in addition to printing the message in the subscribe function, we are now sending it to the Kafka producer as seen below.</p>
<pre><code>def subscribe(client: mqtt_client):
    def on_message(client, userdata, msg):
        print(f&quot;Received `{msg.payload.decode()}` from `{msg.topic}` topic&quot;)
        producer.send('emqx-to-kafka', {&quot;data&quot;: msg.payload.decode()}).add_callback(on_send_success).add_errback(on_send_error)
        # block until all async messages are sent
        producer.flush()
</code></pre>
<p>In the end, kafka consumer will receive a message sent by emqx publisher.</p>
<p><img alt="emqx and kafka merge" src="../../../../images/kafka/emqx-kafka-together.png" /></p>
<p>Therefore, in a real-time situation, the emqx publisher logic will be implemented in IOT devices, which will regularly transmit messages and record real-time data. The data will then be processed by kafka consumers, and we will be able to store and process the data in a backend database.</p>
<p>We will look at storing the messages from the Kafka consumer into the Mango database in the following section.</p>
<h2 id="processing-and-storing-real-time-data-into-mongodb">Processing and storing real time data into mongodb</h2>
<p>In this section, we are going to create a python function using pymongo, a python library to interact with mongo db.
we can create a free account @ https://www.mongodb.com/. By default, we can create a free standard project in mongodb cloud console without paying anything. though there are some restrictions but for a beginer its obsolutely fine to get start.</p>
<p>I am not going to explain how to create cluster/project/database/collection in mongodb in this turotial but i will create a separate document for it in future.</p>
<p>1) Below is my mongo handler which will connect to database and store the messages into "incoming" collection.</p>
<pre><code>from pymongo import MongoClient

def MongoInsertHandler(doc):
    uri             = &quot;mongodb+srv://&lt;username&gt;:&lt;password&gt;@&lt;mongo-endpoint&gt;/?retryWrites=true&amp;w=majority&quot;
    collection_name = &quot;incoming&quot;

    try:
        client = MongoClient(uri)
    # return a friendly error if a URI error is thrown 
    except Exception as e:
        print(e)

    # use a database
    db = client[&quot;emqx-kafka-mongo-app&quot;]

    # use a collection
    my_collection = db[collection_name]

    # INSERT DOCUMENTS
    #
    # In this example, You can insert individual documents using collection.insert_one().
    # If you are creating multiple documents then we can insert them all with insert_many().
    try:
        print(&quot;Inserting document: {}&quot;.format(doc))
        result = my_collection.insert_one(doc)
        print(&quot;Document inserted!&quot;)
    # return a friendly error if the operation fails
    except Exception as e:
        print(e)

# if __name__ == &quot;__main__&quot;:
#     document = {&quot;hello&quot;: &quot;HI&quot;}
#     MongoInsertHandler(document)
</code></pre>
<p>2) As a next step, I will integrate this mongo handler into kafka consumer. When kafka consumer receives message from kafka producer, it will insert that message into mongodb. before calling the mongo handler, I am formatting the data into a json format.</p>
<pre><code>import json
from kafka import KafkaConsumer
from mongo_handler import MongoInsertHandler

# To consume latest messages and auto-commit offsets
# consume json messages
# StopIteration if no message after 1sec
# auto_offset_reset='earliest', enable_auto_commit=False
consumer = KafkaConsumer(bootstrap_servers='localhost:9092',
                         auto_offset_reset='latest', 
                         enable_auto_commit=True,
                         consumer_timeout_ms=1000,
                         value_deserializer=lambda m: json.loads(m.decode('ascii')))

# Subscribe to a regex topic pattern
consumer.subscribe(pattern='^emqx.*')

while True:
    for message in consumer:
        # message value and key are raw bytes -- decode if necessary!
        # e.g., for unicode: `message.value.decode('utf-8')`
        print (&quot;%s:%d:%d: data=%s&quot; % (message.topic, message.partition,
                                            message.offset, message.value))
        document = {&quot;topic&quot;: message.topic, &quot;partition&quot;: message.partition, &quot;offset&quot;: message.offset, &quot;value&quot;: message.value}
        MongoInsertHandler(document)
</code></pre>
<p>In the existing kafka consumer logic, I have appended the below lines in a while loop.</p>
<pre><code>document = {&quot;topic&quot;: message.topic, &quot;partition&quot;: message.partition, &quot;offset&quot;: message.offset, &quot;value&quot;: message.value}
MongoInsertHandler(document)
</code></pre>
<p><img alt="Inserting document" src="../../../../images/mongo/mongo-insert.png" />
As you can see on screen 3, document is getting inserted up on receiving in kafka consumer. In the next image, you can also find the records inserted in the collection in the mongodb cloud console.
<img alt="mongo console" src="../../../../images/mongo/mongo-console.png" /></p>
<h3 style="text-align: center;"> *** End of Tutorial *** </h3>







  
  




  



      
    </article>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["navigation.indexes"], "search": "../../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>